{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58dbc34-7ca7-4edf-83cf-d1be5594156e",
   "metadata": {},
   "source": [
    "# Decision Tree - Heart Disease - to determine top Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221870fe-8f2a-4e80-bcdb-1fabe11cd524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db780d54-a972-4c39-b344-92134c0c7419",
   "metadata": {},
   "source": [
    "# Loading and Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092befb-89a3-4ec5-b384-536e243afe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned preprocessed data\n",
    "heart_data = pd.read_csv(\"resources/heartdisease.csv\")\n",
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542fb605-8b9a-4108-b145-ca2a4178f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further clean data - remove \"Unnamed: 0\" column\n",
    "heart_data = heart_data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Verify\n",
    "heart_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4c2b9-5d67-489e-9112-9affb31d3d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change values\n",
    "heart_data['Diagnosis'].values[heart_data['Diagnosis'] > 0] = 1\n",
    "\n",
    "# Verify\n",
    "heart_data['Diagnosis'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e46a148-7178-4454-9a42-cb5485c55daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Diagnosis column so we only have 0 and 1 (absense and presence)\n",
    "# Copy data\n",
    "heart_new = heart_data.copy()\n",
    "\n",
    "heart_new['Diagnosis'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543993bd-ee6a-426a-844c-ed307b564f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data frame for yes/no diagnosis\n",
    "dgHeartData = heart_data['Diagnosis'].values[heart_data['Diagnosis'] > 0] = 1\n",
    "\n",
    "# Verify\n",
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18088fa-1fde-44be-8a49-e0ee10802d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features set\n",
    "X = heart_data.copy()\n",
    "X.drop('Diagnosis', axis=1, inplace=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e28c3b8-8fc9-4c1c-b726-fe0137df8af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target vector\n",
    "y = heart_data['Diagnosis'].values.reshape(-1, 1)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db57d7-e4ae-4776-82ff-d671396a6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65002d71-0ef6-4582-a625-2148a33ebdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade2a1f-09d1-4536-bc39-1def6107a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Standard Scaller\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a2ac4-5131-4a8f-91c2-afa82257175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d4363-aa1f-47fb-aadf-a2003fa0ac8a",
   "metadata": {},
   "source": [
    "# Fitting the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def28a7-c71e-41a1-9b6f-0bfbb3ab132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the decision tree classifier instance\n",
    "model = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fd51d0-40be-449c-a990-e2baff52a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "model = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6076bb-9011-47e3-9a35-66ee31c79ba1",
   "metadata": {},
   "source": [
    "# Making Predictions Using the Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0313ed3-817d-433a-9917-ccb55d8d65a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data\n",
    "predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6240497d-4b4e-450a-b23b-385b362788a5",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a256793-d7fd-43a9-bb67-2283f7558b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2a8da-7d25-4a79-8a98-c6e02df86ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a8d26-2fbe-48ec-ba95-c2bc496950cd",
   "metadata": {},
   "source": [
    "# Fitting the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5243998e-e3d8-4cb2-8ddc-47c0cd8e8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b2b489-2d51-4c02-95ae-9ec7d3eb15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210d1d54-3d5e-4127-85a3-c9362e2590ce",
   "metadata": {},
   "source": [
    "# Making Predictions Using the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c09bd3-a54b-435e-a5dd-f631f8e2967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data\n",
    "predictions = rf_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7ea3b0-0401-4232-b9dc-a31e030588ab",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db8eed6-fa9e-43a2-bfdc-df39b53a6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99bcbc5-a2fc-4474-936c-f92e48a83869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88642f99-7ad3-415f-a056-7e0ac1a7bd05",
   "metadata": {},
   "source": [
    "# Feature Importance - Max Heart Rate and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f3056f-ab31-4a78-8cd3-a0123ecb7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests in sklearn will automatically calculate feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "# We can sort the features by their importance\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93930c21-97e0-415f-8ff0-2f7ce9d657ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the features by importance\n",
    "importances_df = pd.DataFrame(sorted(zip(rf_model.feature_importances_, X.columns), reverse=True))\n",
    "importances_df.set_index(importances_df[1], inplace=True)\n",
    "importances_df.drop(columns=1, inplace=True)\n",
    "importances_df.rename(columns={0: 'Feature Importances'}, inplace=True)\n",
    "importances_sorted = importances_df.sort_values(by='Feature Importances')\n",
    "importances_sorted.plot(kind='barh', color='lightgreen', title= 'Features Importances', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec17fe19-ce09-4236-b488-052b557e27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "uniqueValues = heart_data.nunique()\n",
    "uniqueValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f0b0a9-a95e-44e9-8c58-9f69f001d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at  value counts to identify and delete.\n",
    "MaxRate_Type = heart_data['Max Heart Rate'].value_counts()\n",
    "Sorted_MaxRate = MaxRate_Type.sort_values(ascending=False)\n",
    "Sorted_MaxRate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527304e-d24e-414e-bd6d-c10ba6fbe791",
   "metadata": {},
   "source": [
    "# Pre-Process Data and create Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe582b4-59e6-4a71-bf8d-d7484af871ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at Max Rate frequency less than 53 to remove 0 values. \n",
    "Sorted_MaxRate53 = Sorted_MaxRate[Sorted_MaxRate < 53]\n",
    "Sorted_MaxRate53.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04943571-4e8e-4a36-83aa-b68cd1b2b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "MaxRate_cutoff = 19\n",
    "mr19 = heart_data['Max Heart Rate'].value_counts()\n",
    "mr_to_replace = list(mr19[mr19 > MaxRate_cutoff].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for mr in mr_to_replace:\n",
    "    heart_data['Max Heart Rate'] = heart_data['Max Heart Rate'].replace(mr,\"Other\")\n",
    "\n",
    "# Check to make sure replacement was successful\n",
    "heart_data['Max Heart Rate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8395093d-6060-4a02-9e07-52ed484a5ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at  value counts to identify and delete.\n",
    "ages = heart_data['Age'].value_counts()\n",
    "Sorted_Ages = ages.sort_values(ascending=False)\n",
    "Sorted_Ages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f601e3e-a810-4ac6-84f4-5284a1b44d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert categorical Data to numeric with 'pd.get_dummies'\n",
    "converted_heart_data = pd.get_dummies(heart_data)\n",
    "converted_heart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4ff43-ad8d-42b4-a99d-e6aeb3b7b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split our preprocessed data into our features and target arrays\n",
    "X = converted_heart_data.drop('Diagnosis', axis=1).values\n",
    "y = converted_heart_data['Diagnosis'].values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a2dd3a-c3b6-4798-9d36-a8b3a2ce449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3ddc8d-e142-41f8-a186-62b4a54762bb",
   "metadata": {},
   "source": [
    "# Run Neural Net for Feature importances - Max Heart Rate and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15189352-058b-4c4d-b465-7dcc823a8b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 90\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation = 'relu')\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation='leaky_relu'))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7f7ff3-56d1-4b60-ab6e-ab43c7593df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf5670e-01f3-4fd7-983a-079ab0b49121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fitModel = nn.fit(X_train_scaled, y_train, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e76554-6e96-442e-9ed9-f65104a43918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
